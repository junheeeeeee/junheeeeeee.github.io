<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Vision AI for Industrial Safety | Jun-Hee  Kim</title>
    <meta name="author" content="Jun-Hee  Kim">
    <meta name="description" content="Real-time 3D human pose estimation and open-vocabulary object detection using vision–language learning (R&amp;D project).">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://junheeeeeee.github.io/projects/industry/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jun-Hee </span>Kim</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Vision AI for Industrial Safety</h1>
            <p class="post-description">Real-time 3D human pose estimation and open-vocabulary object detection using vision–language learning (R&amp;D project).</p>
          </header>

          <article>
            <h2 id="summary">Summary</h2>
<p>This project develops two core vision AI capabilities for industrial environments:</p>

<p>1) <strong>Real-time 3D Human Pose Estimation (3D HPE)</strong> from video to monitor worker posture and support safety-oriented alerts and explanations. :contentReference[oaicite:2]{index=2}<br>
2) <strong>Open-Vocabulary / Open-Set Object Detection (OVOD)</strong> leveraging cross-modal vision–language learning to detect novel objects by adjusting text prompts rather than retraining the detector. :contentReference[oaicite:3]{index=3}</p>

<p>The goal is to build adaptable, deployment-ready models that generalize across diverse sites, tasks, and changing object requirements.</p>

<h2 id="motivation">Motivation</h2>
<p>Industrial sites are highly dynamic: worker posture risks vary by task, and the set of objects to detect changes frequently across environments. Traditional pipelines require costly data collection and retraining whenever conditions shift. This project focuses on (a) robust posture understanding in real time and (b) language-driven adaptability for object detection.</p>

<h2 id="objectives">Objectives</h2>
<h3 id="1-3d-human-pose-estimation-video--3d-joints">1) 3D Human Pose Estimation (Video → 3D Joints)</h3>
<ul>
  <li>Predict 3D joint coordinates from real-time video streams to support posture monitoring and safety guidance. :contentReference[oaicite:4]{index=4}</li>
  <li>Improve accuracy and robustness to be applicable across diverse industrial scenarios. :contentReference[oaicite:5]{index=5}</li>
</ul>

<h3 id="2-open-vocabulary--open-set-object-detection-vision--language">2) Open-Vocabulary / Open-Set Object Detection (Vision + Language)</h3>
<ul>
  <li>Extend closed-set object detection to open-set settings by integrating <strong>vision–language cross-modal information</strong>. :contentReference[oaicite:6]{index=6}</li>
  <li>Enable rapid adaptation to new environments/objects by <strong>editing language inputs</strong> instead of replacing or retraining the base detector. :contentReference[oaicite:7]{index=7}</li>
</ul>

<h2 id="method">Method</h2>

<h3 id="workstream-a-real-time-3d-human-pose-estimation">Workstream A: Real-Time 3D Human Pose Estimation</h3>
<ul>
  <li>
<strong>Input/Output</strong>: video frames → 3D joint coordinates (per frame / temporal sequence).</li>
  <li>
<strong>Modeling strategy</strong>
    <ul>
      <li>Evaluate end-to-end 3D estimation and/or two-stage pipelines (2D keypoints → 3D lifting), selecting the most deployable approach for real-time constraints.</li>
      <li>Add temporal stabilization and filtering strategies to reduce jitter and improve consistency in streaming settings.</li>
    </ul>
  </li>
  <li>
<strong>System integration</strong>
    <ul>
      <li>Provide posture signals that can be used for downstream safety logic (e.g., risky bending, hazardous reach, unsafe handling posture), enabling alerts and explanatory feedback.</li>
    </ul>
  </li>
</ul>

<h3 id="workstream-b-open-vocabulary--open-set-object-detection-via-visionlanguage-learning">Workstream B: Open-Vocabulary / Open-Set Object Detection via Vision–Language Learning</h3>
<ul>
  <li>
<strong>Core idea</strong>
    <ul>
      <li>Fuse visual features with language embeddings to detect objects beyond a fixed set of trained categories. :contentReference[oaicite:8]{index=8}</li>
    </ul>
  </li>
  <li>
<strong>Adaptation without retraining</strong>
    <ul>
      <li>When the target set changes (new site / new objects), update detection behavior through <strong>text prompts or language inputs</strong> rather than retraining the detector. :contentReference[oaicite:9]{index=9}</li>
    </ul>
  </li>
  <li>
<strong>Deployment focus</strong>
    <ul>
      <li>Maintain a strong closed-set baseline while enabling open-set expansion through language conditioning.</li>
    </ul>
  </li>
</ul>

<h2 id="data--annotation-high-level">Data &amp; Annotation (High-Level)</h2>
<ul>
  <li>
<strong>3D HPE</strong>
    <ul>
      <li>Video data annotated or prepared to support 3D joint supervision and evaluation for posture-centric tasks. :contentReference[oaicite:10]{index=10}</li>
    </ul>
  </li>
  <li>
<strong>OVOD</strong>
    <ul>
      <li>Detection datasets supporting both closed-set performance and open-set evaluation, with text descriptions/class names used as language supervision. :contentReference[oaicite:11]{index=11}</li>
    </ul>
  </li>
</ul>

<p>(Details such as data sources, labeling policies, and internal evaluation splits are omitted due to confidentiality.)</p>

<h2 id="deliverables">Deliverables</h2>
<ul>
  <li>A real-time 3D pose estimation module that outputs 3D joints from video for posture monitoring and safety applications. :contentReference[oaicite:12]{index=12}</li>
  <li>An open-vocabulary object detection module that integrates vision–language signals and supports language-only adaptation to new objects/environments. :contentReference[oaicite:13]{index=13}</li>
  <li>Dataset/annotation guidelines and a reproducible training–evaluation recipe for both workstreams (internal use).</li>
</ul>

<h2 id="evaluation-confidential">Evaluation (Confidential)</h2>
<p>Quantitative results and internal benchmarks are not publicly shareable due to confidentiality constraints.<br>
Results can be shared upon request under an NDA.</p>

<h2 id="my-role-edit-as-needed">My Role (edit as needed)</h2>
<ul>
  <li>Contributed to end-to-end project planning and technical design across both workstreams (3D HPE and OVOD). :contentReference[oaicite:14]{index=14} :contentReference[oaicite:15]{index=15}</li>
  <li>Supported dataset construction and annotation workflows, including labeling requirements and quality checks.</li>
  <li>Collaborated with stakeholders to iterate on requirements and deployability constraints for real-world industrial environments.</li>
</ul>

<h2 id="tech-stack-high-level">Tech Stack (high-level)</h2>
<ul>
  <li>3D human pose estimation from video (real-time posture monitoring)</li>
  <li>Vision–language cross-modal learning for open-vocabulary detection</li>
  <li>Deployment-oriented model integration and data/annotation pipelines</li>
</ul>

<hr>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2026 Jun-Hee  Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
